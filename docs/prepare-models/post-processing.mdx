---
title: "Prepare post-processing model"
lang: "en-US"
draft: false
description: "Learn about how to prepare a post-processing Python model for the open-source visual data ETL tool VDP https://github.com/instill-ai/vdp"
---

## Standardise post-processing output format

You can prepare the post-processing model the same way as the [pre-processing model](pre-processing). However, to get the model inference output in a standarised format you can

- specify a [supported CV Task](/docs/core-concepts/cv-task) when creating the [model card](model-card)
- create a Python model that inherits the corresponding post-processing task class in [triton_python_model](https://github.com/instill-ai/triton-python-model).

If no task is specified when creating a model, the output will the raw model output in a [serialized JSON message](/docs/core-concepts/cv-task#how-to-standardise).

### Image classification

:::info{type=info}
Learn more about [Image classification Task](/docs/core-concepts/cv-task#image-classification)
:::

Assume we have a "cat vs. dog" model to infer whether an image is a cat image or dog image. Create a `labels.txt` file to list all the pre-defined categories, with one category label per line. Add the file to the folder of inference model.

**`labels.txt` example**

```
cat
dog
```

Include the label file `labels.txt` in the model configuration of the inference model.

**`config.pbtxt` example**

```
...
output [
  {
    ...
    label_filename: "labels.txt"
  }
]
...
```

Check the [standarised output for image classification](/docs/core-concepts/cv-task#image-classification), here shows an output example:

```json
{
  "task": "TASK_CLASSIFICATION",
  "task_outputs": [
    {
      "classification": {
          "category": "dog",
          "score": 1
      }
    }
  ]
}
```

### Object detection

:::info{type=info}
Learn more about [Object detection Task](/docs/core-concepts/cv-task#object-detection)
:::

Create a Python file with a structure similar to below. The file inherits the `PostDetectionModel` class and implement the `post_process_per_image` abstract method.
Then, add the file in the post-processing model folder:

```python model.py
import numpy as np
from triton_python_model.task.detection import PostDetectionModel


class TritonPythonModel(PostDetectionModel):
    """Your Python model must use the same class name.
    Every Python model that is created must have "TritonPythonModel" as the class name.
    """
    def __init__(self):
        """ Constructor function must be implemented in every model.
        This function initializes the names of the input and output
        variables in the model configuration.
        """
        # super().__init__(input_names=[...], output_names=[...])
        # ...

    def post_process_per_image(self, inputs):
        """`post_process_per_image` must be implemented in every Python model.
        This function receives a sequence of the input array of the model for
        one image of a batch, converts and returns the a sequence of array
        `bboxes` and `labels`.
          - `bboxes` represents the detected bounding boxes and scores.
          - `labels` represents the corresponding category label for each bounding box.

        Parameters
        ----------
        inputs: Tuple[np.ndarray]
          a sequence of Input array of one image

        Returns
        -------
        Tuple[np.ndarray]
          - `bboxes`: bounding boxes detected in this image with shape (n,5) or (0,).
             The bounding box format is [x1, y1, x2, y2, score] in the image.
          - `labels`: labels corresponding to the bounding boxes with shape (n,) or (0,),
             where `n` is the number of categories.

          The length of `bboxes` must be the same as that of `labels`.
        """
        # return np.array([[324, 102, 532, 507, 0.98]]), np.array(["dog"]) # Dummy detection example

```

Check the [standardised output for object detection](/docs/core-concepts/cv-task#object-detection), here shows an output example:

```json
{
  "task": "TASK_DETECTION",
  "task_outputs": [
    {
      "detection": {
        "objects": [
          {
            "category": "dog",
            "score": 1,
            "bounding_box": {
              "top": 10,
              "left": 20,
              "width": 120,
              "height": 50
            }
          }
        ]
      }
    }
  ]
}
```

### Keypoint detection

:::info{type=info}
Learn more about [Keypoint detection Task](/docs/core-concepts/cv-task#keypoint-detection)
:::

Create a Python file with a structure similar to below and add the file in the post-processing model folder:

```python model.py
import numpy as np
from triton_python_model.task.keypoint import PostKeypointDetectionModel


class TritonPythonModel(PostKeypointDetectionModel):
    """Your Python model must use the same class name.
    Every Python model that is created must have "TritonPythonModel" as the class name.
    """
    def __init__(self):
        """ Constructor function must be implemented in every model.
        This function initializes the names of the input and output
        variables in the model configuration.
        """
        # super().__init__(input_names=[...], output_names=[...])
        # ...

    def post_process_per_image(self, inputs):
        """`post_process_per_image` must be implemented in every Python model.
        This function receives a sequence of the input array of the model for
        one image of a batch, converts and returns the a sequence of array
        `bboxes` and `labels`.
          - `bboxes` represents the detected bounding boxes and scores.
          - `labels` represents the corresponding category label for each bounding box.

        Parameters
        ----------
        inputs: Tuple[np.ndarray]
          a sequence of Input array of one image

        Returns
        -------
        Tuple[np.ndarray]
          - `bboxes`: bounding boxes detected in this image with shape (n,5) or (0,).
             The bounding box format is [x1, y1, x2, y2, score] in the image.
          - `labels`: labels corresponding to the bounding boxes with shape (n,) or (0,),
             where `n` is the number of categories.

          The length of `bboxes` must be the same as that of `labels`.
        """
        # return np.array([[324, 102, 532, 507, 0.98]]), np.array(["dog"]) # Dummy detection example

```

Check the [standardised output for keypoint detection](/docs/core-concepts/cv-task#keypoint-detection), here shows an output example:

```json
{
  "task": "TASK_KEYPOINT",
  "task_outputs": [
    {
      "keypoint": {
        "objects": [
          {
            "keypoints": [
              {
                  "x": 0,
                  "y": 0,
                  "v": 1
              },
              {
                  "x": 1,
                  "y": 1,
                  "v": 1
              },
              {
                  "x": 2,
                  "y": 2,
                  "v": 1
              },
              {
                  "x": 3,
                  "y": 3,
                  "v": 1
              },
              {
                  "x": 4,
                  "y": 4,
                  "v": 1
              },
              {
                  "x": 5,
                  "y": 5,
                  "v": 1
              },
              {
                  "x": 6,
                  "y": 6,
                  "v": 1
              },
              {
                  "x": 7,
                  "y": 7,
                  "v": 1
              },
              {
                  "x": 8,
                  "y": 8,
                  "v": 1
              },
              {
                  "x": 9,
                  "y": 9,
                  "v": 1
              },
              {
                  "x": 10,
                  "y": 10,
                  "v": 1
              },
              {
                  "x": 11,
                  "y": 11,
                  "v": 1
              },
              {
                  "x": 12,
                  "y": 12,
                  "v": 1
              },
              {
                  "x": 13,
                  "y": 13,
                  "v": 1
              },
              {
                  "x": 14,
                  "y": 14,
                  "v": 1
              },
              {
                  "x": 15,
                  "y": 15,
                  "v": 1
              },
              {
                  "x": 16,
                  "y": 16,
                  "v": 1
              }
            ],
            "score": 0.98,
            "bounding_box": {
              "top": 10,
              "left": 10,
              "width": 100,
              "height": 100
            }
          }
        ]
      }
    }
  ]
}
```

### Instance Segmentation CV Task

:::info{type=info}
Learn more about [Instance Segmentation CV Task](/docs/core-concepts/cv-task#instance-segmentation)
:::

Check the [standardised output for Instance Segmentation CV Task](/docs/core-concepts/cv-task#instance-segmentation), here shows an output example:

```json
{
  "task": "TASK_INSTANCE_SEGMENTATION",
  "task_outputs": [
    {
      "instance_segmentation": {
        "objects": [
          {
            "rle": "49,29,264,29,479,29,694,29,909,29,1124,29,1339,29,1554,30,1768,32,1982,34,2195,38,2409,41,2621,47,2833,54,3045,63,3259,69,3472,74,3686,76,3900,78,4114,81,4329,81,4543,83,4757,85,4972,86,5186,88,5401,89,5615,91,5829,93,6043,96,6257,99,6472,100,6686,102,6900,104,7114,106,7329,106,7543,108,7758,109,7973,109,8187,111,8402,112,8617,114,8832,115,9047,117,9261,120,9476,123,9691,125,9906,126,10120,129,10335,129,10550,130,10765,130,10979,132,11194,132,11409,132,11623,134,11838,134,12052,135,12267,136,12481,137,12696,138,12910,139,13125,139,13340,140,13555,140,13769,142,13984,142,14199,142,14414,141,14629,141,14844,141,15059,141,15274,141,15489,141,15704,141,15919,140,16134,140,16348,141,16563,141,16778,141,16993,141,17208,141,17423,141,17638,140,17853,140,18068,140,18283,140,18498,140,18713,140,18929,138,19144,138,19359,138,19574,138,19789,138,20004,138,20219,138,20434,137,20649,137,20865,136,21080,136,21296,135,21511,134,21727,133,21942,133,22158,132,22374,130,22589,130,22805,129,23020,128,23235,128,23451,127,23666,127,23881,127,24097,126,24312,127,24527,127,24743,126,24958,126,25174,125,25390,124,25605,124,25821,123,26037,122,26252,123,26467,123,26682,123,26897,124,27112,125,27328,124,27543,125,27758,126,27973,127,28188,129,28403,129,28618,130,28833,131,29048,131,29263,132,29478,132,29693,132,29908,133,30123,133,30337,135,30552,136,30767,136,30982,137,31197,138,31411,139,31626,140,31841,140,32055,141,32270,142,32485,142,32699,143,32914,144,33129,144,33344,144,33558,145,33773,145,33988,146,34203,146,34417,147,34632,148,34847,148,35062,148,35277,149,35491,150,35706,151,35921,151,36136,151,36351,152,36566,152,36780,153,36995,153,37210,153,37425,154,37639,155,37854,155,38069,155,38283,156,38498,157,38712,158,38927,158,39142,158,39356,159,39571,159,39786,160,40001,160,40215,161,40430,161,40645,161,40860,162,41075,162,41290,162,41504,163,41719,164,41934,164,42149,164,42364,165,42579,165,42794,165,43009,166,43224,166,43439,167,43654,167,43869,167,44084,167,44299,168,44514,168,44729,168,44944,168,45159,168,45374,169,45589,169,45804,169,46019,169,46234,170,46449,170,46664,170,46880,169,47095,170,47310,170,47525,170,47740,171,47955,171,48170,172,48385,172,48600,173,48815,173,49031,172,49246,173,49461,173,49676,173,49892,173,50107,173,50322,173,50538,172,50753,173,50968,173,51183,173,51399,172,51614,173,51829,173,52045,172,52260,173,52475,173,52690,174,52905,174,53121,174,53336,174,53551,175,53766,175,53981,176,54197,175,54412,175,54627,175,54842,176,55058,175,55273,175,55488,175,55704,175,55919,175,56135,174,56350,175,56566,174,56781,175,56997,174,57212,174,57427,175,57643,174,57858,175,58073,175,58289,175,58504,175,58719,175,58935,175,59150,175,59365,176,59581,175,59796,175,60012,175,60227,175,60443,174,60658,175,60874,174,61089,174,61305,174,61520,174,61735,175,61951,175,62166,175,62382,175,62597,175,62813,174,63028,175,63243,175,63459,174,63674,175,63890,174,64105,174,64321,173,64536,173,64751,173,64967,172,65182,172,65398,172,65613,172,65828,172,66043,172,66259,171,66474,171,66689,171,66904,171,67119,171,67335,170,67550,170,67765,170,67980,170,68195,169,68410,169,68625,169,68840,169,69055,169,69270,169,69485,169,69701,167,69916,167,70131,167,70346,167,70561,166,70776,166,70991,166,71206,165,71421,164,71636,164,71851,163,72067,161,72282,160,72497,160,72712,159,72927,159,73142,159,73357,158,73572,158,73787,157,74003,155,74218,155,74433,154,74648,153,74863,152,75078,151,75293,151,75509,149,75724,149,75939,148,76154,148,76369,147,76584,147,76800,74,76878,67,77015,72,77096,64,77230,70,77313,61,77446,67,77528,61,77661,59,77743,60,77876,42,77958,59,78091,41,78174,58,78307,39,78389,57,78522,38,78604,57,78737,37,78819,56,78952,36,79034,56,79167,35,79250,55,79383,33,79465,54,79598,33,79680,54,79813,33,79895,54,80028,32,80110,53,80244,31,80325,53,80459,30,80540,53,80675,29,80755,52,80890,28,80970,52,81106,27,81185,51,81321,26,81400,51,81537,25,81615,50,81753,23,81830,50,81968,23,82045,50,82184,21,82261,48,82400,19,82476,48,82615,18,82691,48,82831,16,82906,47,83046,14,83121,47,83262,11,83336,47,83478,7,83551,46,83766,46,83982,44,84197,44,84412,43,84627,43,84842,42,85057,41,85273,39,85488,39,85703,38,85918,38,86133,38,86348,38,86563,38,86778,38,86993,38,87208,38",
            "score": 0.9979786,
            "bounding_box": {
              "top": 95,
              "left": 320,
              "width": 215,
              "height": 406
            },
            "label": "dog"
          },
          {
            "rle": "52,31,249,31,446,31,643,31,840,31,1035,35,1229,40,1423,46,1615,55,1808,62,2002,67,2198,70,2394,72,2590,74,2786,76,2982,79,3177,83,3372,88,3566,93,3761,98,3957,100,4153,102,4349,104,4546,105,4742,106,4937,109,5133,111,5328,114,5524,116,5720,117,5917,118,6113,120,6309,121,6506,121,6699,125,6896,126,7093,126,7290,126,7487,126,7684,126,7881,126,8078,126,8275,126,8472,126,8669,126,8866,125,9063,125,9260,125,9457,125,9654,124,9851,123,10048,123,10249,118,10447,116,10645,115,10842,114,11040,113,11237,112,11435,111,11633,109,11831,107,12029,105,12228,102,12426,100,12624,98,12822,96,13020,94,13218,92,13416,90,13614,88,13812,86,14010,85,14208,83,14407,80,14604,80,14802,78,15000,77,15197,76,15395,75,15592,74,15790,73,15988,71,16185,71,16383,70,16580,69,16778,68,16975,69,17172,69,17369,69,17566,69,17764,68,17961,68,18158,69,18355,69,18552,70,18749,71,18946,71,19142,73,19339,74,19536,75,19733,75,19930,76,20126,78,20323,79,20520,80,20716,81,20913,82,21110,82,21306,84,21503,84,21700,85,21897,85,22094,86,22290,87,22487,88,22684,89,22881,90,23077,92,23274,92,23471,92,23668,93,23865,93,24061,94,24258,95,24455,95,24651,96,24848,97,25044,98,25241,99,25438,99,25634,101,25831,102,26028,102,26225,103,26421,104,26618,105,26815,105,27012,106,27209,106,27406,107,27603,107,27800,108,27996,110,28193,111,28390,112,28587,112,28784,112,28981,113,29178,113,29375,113,29572,113,29769,114,29966,114,30163,115,30360,115,30557,115,30754,116,30951,117,31148,117,31345,118,31542,118,31739,119,31936,119,32133,119,32330,120,32527,120,32724,120,32921,120,33118,121,33315,121,33512,121,33709,122,33906,122,34103,123,34300,124,34497,124,34694,125,34891,126,35088,126,35285,126,35482,127,35679,127,35876,128,36073,128,36270,129,36467,129,36664,130,36861,132,37058,133,37255,133,37452,134,37649,135,37846,135,38043,136,38240,136,38437,137,38634,138,38831,138,39028,139,39225,140,39422,140,39619,140,39816,141,40013,141,40210,141,40407,142,40571,12,40604,142,40767,13,40801,143,40963,14,40998,143,41159,15,41196,143,41356,15,41393,143,41552,16,41590,145,41749,16,41787,147,41945,17,41984,148,42142,17,42181,149,42336,20,42378,150,42531,22,42575,175,42772,91,42867,80,42969,77,43066,78,43167,62,43267,74,43364,57,43467,71,43562,53,43667,68,43759,50,43866,66,43957,27,43985,18,44065,64,44155,22,44185,13,44263,63,44353,18,44385,7,44461,57,44551,15,44659,43,44704,8,44749,12,44857,37,44948,4,45055,34,45253,32,45451,30,45649,28,45847,27,46044,26,46242,24,46440,22,46638,20,46837,17,47036,13,47235,9",
            "score": 0.9728953,
            "bounding_box": {
              "top": 194,
              "left": 130,
              "width": 197,
              "height": 248
            },
            "label": "dog"
          }
        ]
      }
    }
  ]
}
```

### Unspecified CV Task

:::info{type=info}
Learn more about [Unspecified CV Task](/docs/core-concepts/cv-task#what-if-my-task-is-not-standardised-by-by-vdp-yet)
:::

If your model is imported without specifying any Task metadata, the model will be recognised to solve an `Unspecified` CV Task.
There is no need to prepare your model outputs to fit any format.

Check the [standardised output for Unspecified CV Task](/docs/core-concepts/cv-task#what-if-my-task-is-not-standardised-by-by-vdp-yet).
Assume we import the above ["cat vs. dog"](#image-classification) model without specifying the CV Task metadata, here shows an output example:

```json
{
  "task": "TASK_UNSPECIFIED",
  "task_outputs": [
    {
      "unspecified": {
        "raw_outputs": [
          {
            "data": [
              0,
              1
            ],
            "data_type": "FP32",
            "name": "output",
            "shape": [
              2
            ]
          }
        ]
      }
    }
  ]
}
```
