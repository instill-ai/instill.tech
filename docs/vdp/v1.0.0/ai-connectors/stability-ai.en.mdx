---
title: "Stability AI"
lang: "en-US"
draft: false
description: "Learn about how to set up a Stability AI AI connector for the unstructured data pipeline tool VDP https://github.com/instill-ai/vdp"
---

The Stability AI AI connector enables you to connect the AI models served on the Stability AI Platform for the **Text to Image** and **Image to Image** AI tasks.

## Release stage

`Alpha`

## Configuration

The up-to-date configuration is maintained [here](https://github.com/instill-ai/connector-ai/blob/main/pkg/stabilityai/config/seed/definitions.json).

| Field     | Type   | Note                                                                                       |
| :-------- | :----- | :----------------------------------------------------------------------------------------- |
| api_key\* | string | Enter your Stability AI API key. To find your keys, go to your DreamStudio's Account page. |

### No-code setup

<InfoBlock type="info" title="Prerequisites">

To create a Stability AI AI connector, you'll first need to create a
Stability AI account by visiting [dreamstudio.ai](https://dreamstudio.ai).
Access to your API keys can then be managed through DreamStudio's Account
page. All new users are granted 25 free credits upon creating an account.

ðŸ‘‰ Alternatively, you can try out [Instill Cloud](https://console.instill.tech)
to use our pre-created Stability AI AI connector for FREE during Open Alpha.

</InfoBlock>

To create a Stability AI AI connector:

1. Go to the **AI** page and click **Set up new AI**
2. In the **Set Up New AI Connector** page, fill an ID for your model, this will be the unique identifier of this connector
3. [Optional] Give a short description of your connector in the **Description** field
4. Click the **AI Connector Type** â–¾ drop-down and choose **Stability AI**
5. Fill the following information and click **Set up**

   - Fill **API Key**. Follow the Stability AI [documentation](https://platform.stability.ai/docs/getting-started/authentication) to find your API key

6. By default, the connector is disconnected. To connect and use AI connector, go to the connector page and click **Connect**.

### Low-code setup

1. Create a Stability AI AI connector

<CH.Code>
```shellscript cURL
curl  --location http://localhost:8080/vdp/v1alpha/users/<user_id>/connector-resources
      --header 'Authorization: Bearer <Your-API-Token>' \
      --data '{
        "id": "my-stable-diffusion-xl-1024-v1-0",
        "connector_definition_name": "connector-definitions/ai-stability-ai",
        "configuration": {
          "api_key": "<stability-ai-api-key>"
        }
      }'
```
</ CH.Code>


For other operations, please refer to the [VDP Protobufs](https://buf.build/instill-ai/protobufs).

## Expected inputs and outputs

When using the Stability AI AI connector in your pipeline, certain fields of the input data need to be filled to trigger the pipeline effectively.
Here are the expected input and output data fields for the Stability AI AI connector.

### Expected input data fields

| Input data field              | Type          | Description                                                                                                       |
| :---------------------------- | ------------- | ----------------------------------------------------------------------------------------------------------------- |
| task                          | string        | "TASK_TEXT_TO_IMAGE" or "TASK_IMAGE_TO_IMAGE"                                                                     |
| engine                        | string        | Stability AI Engine (model) to be used. eg. stable-diffusion-xl-1024-v1-0, stable-diffusion-v1                    |
| init_image                    | string        | This is only required for "TASK_IMAGE_TO_IMAGE" task to specify initial image                                     |
| prompts                       | array[string] | This has the text prompt, required for all tasks.                                                                 |
| cfg_scale                     | number        | How strictly the diffusion process adheres to the prompt text, optional for all tasks.                            |
| clip_guidance_preset          | string        | One from: FAST_BLUE, FAST_GREEN, NONE, SIMPLE, SLOW, SLOWER, SLOWEST, optional for all tasks.                     |
| sampler                       | string        | Which sampler to use for the diffusion process, optional for all tasks.                                           |
| samples                       | integer       | Number of images to generate, optional for all tasks.                                                             |
| seed                          | integer       | Random noise seed, optional for all tasks.                                                                        |
| steps                         | integer       | Number of diffusion steps to run, optional for all tasks.                                                         |
| style_preset                  | string        | To guide the image model towards a particular style, optional for all tasks.                                      |
| weights                       | array[number] | Weights for each of the prompts in texts, optional for all tasks.                                                 |
| height                        | integer       | Height of the output image, optional but only for "TASK_TEXT_TO_IMAGE" task.                                      |
| width                         | integer       | Width of the output image, optional but only for "TASK_TEXT_TO_IMAGE" task.                                       |
| init_image_mode               | string        | Whether to use image_strength or step_schedule, optional but only for "TASK_IMAGE_TO_IMAGE" task.                 |
| image_strength                | number        | How much influence the init_image has on the diffusion process, optional but only for "TASK_IMAGE_TO_IMAGE" task. |

Example input data for **TASK_TEXT_TO_IMAGE** and **TASK_IMAGE_TO_IMAGE** tasks:

<CH.Code>
```json text-to-image
{
  "prompts": [
    "black dog",
  ],
  "cfg_scale": 7.0,
  "clip_guidance_preset": "SLOWER",
  "samples": 3,
  "style_preset": "cinematic",
  "weights": [0.5, 0.7],
  "height": 512,
  "width": 512
}
```

```json image-to-image(with-url)
{
  "prompts": ["crayon drawing of dogs sit in the snow"],
  "init_image": "<base64 encode string>",
  "steps": 50,
  "cfg_scale": 7.0,
  "clip_guidance_preset": "SIMPLE",
  "style_preset": "anime",
  "init_image_mode": "IMAGE_STRENGTH",
  "seed": 16258,
  "samples": 1,
  "image_strength": 0.35,
  "weights": [0.65]
}
```
</ CH.Code>

### Expected output data fields

| Output data field | Type            | Description                                                  |
| :---------------- | --------------- | ------------------------------------------------------------ |
| images            | array[image]    | This will contain the output images as base64 encoded string.|
| seeds             | array[integer]  | This will contain the seeds for output images.               |

Example output data:

```json
{
  "images": ["<base64-encoded image>"]
}
```
