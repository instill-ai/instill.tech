---
title: "Use Models"
lang: "en-US"
draft: false
description: "Learn about how to use Models served on Instill Model https://github.com/instill-ai/model"
---

<InfoBlock type="tip" title="tip">
  An **inference** is a prediction to a question or task. In the concept of
  Machine Learning (ML) and Artificial Intelligence (AI), the term inference is
  often compared with training. To put it simple, inference is where
  capabilities learnt during training are put to analyze data to "infer" a
  result. Inference can be found and are applied everywhere across industries
  from photo tagging to autonomous driving.
</InfoBlock>

_Instill Model provides an automated model inference server._

## Inference with Dedicated Model API Endpoint

After a pushed model version is deployed, it dynamically generates a dedicated API endpoint for model inference `/users/<user-id>/models/<model-id>/versions/<version-id>/trigger`.

You can send multiple images of popular formats (PNG and JPEG) in one request to the generated model API endpoint.
Check the examples below. The API accepts batched images

- sent by remote URL and Base64 or
- uploaded by multipart.

<CH.Code>

```shellscript cURL(url)
curl -X POST http://localhost:8080/v1alpha/users/<user-id>/models/<model-id>/versions/<version-id>/trigger \
--header 'Authorization: Bearer instill_sk_***' \
--data '{
    "task_inputs": [
        {
            "classification": {
                "image_url": "https://artifacts.instill.tech/imgs/dog.jpg"
            }
        },
        {
            "classification": {
                "image_url": "https://artifacts.instill.tech/imgs/bear.jpg"
            }
        }
    ]
}'
```

```shellscript cURL(base64)
curl -X POST http://localhost:8080/v1alpha/users/<user-id>/models/<model-id>/versions/<version-id>/trigger \
--data '{
    "task_inputs": [
        {
            "classification": {
                "image_base64": "/9j/4AAQSkZ...iiigD/2Q=="
            }
        },
        {
            "classification": {
                "image_base64": "/9j/4AAQSkZ...iiigD/2Q=="
            }
        }
    ]
}'
```

```shellscript cURL(multipart)
curl -X POST http://localhost:8080/v1alpha/users/<user-id>/models/<model-id>/versions/<version-id>/trigger-multipart \
--header 'Authorization: Bearer instill_sk_***' \
--form 'file=@"dog.jpg"' \
--form 'file=@"bear.jpg"'
```

</CH.Code>

The `<user-id>`, `<model-id>` and `<version-id>` correspond to the namespace, ID and version tag of a model.

## Using Models in VDP

To build VDP pipelines for your AI workflows with models served on Instill Model platform,
you can utilize the [Instill Model AI Connector](../component/ai/instill).
