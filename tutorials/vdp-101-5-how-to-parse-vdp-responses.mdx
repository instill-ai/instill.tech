---
title: "VDP 101 - 5. How to Parse Responses from SYNC Pipelines"
lang: "en-US"
draft: false
description: "In the `SYNC` mode, VDP returns post-processed inference results depending on the protocol (i.e., `HTTP/gRPC`) you use to trigger the pipeline. In this tutorial, we will use the HTTP protocol as an example to demonstrate how to understand and parse the responses from VDP."
aiTask: "objectDetection"
sourceConnector: "HTTP"
destinationConnector: "HTTP"
publishedOn: "2023-01-30T17:26:00"
placeholderColor: "bg-instillYellow50"
themeImgSrc: "/tutorial-assets/vdp-101/cover-animation.gif"
themeImgThumbnailSrc: "/tutorial-assets/vdp-101/cover-static.png"
useCase: "Prototyping"
author: "Po-Yu Chen"
authorAvatarSrc: "/author-avatar/po-yu-chen.jpg"
authorGitHubUrl: "https://github.com/bryan107"
---

In the previous tutorial [VDP 101 - 4. How to Trigger a SYNC Pipeline?](/tutorials/vdp-101-4-how-to-trigger-a-sync-pipeline), you have learned how to trigger and send data to the pipeline. However, we haven't talked about how to process it. In the `SYNC` mode, VDP returns post-processed inference results according to the protocol (i.e., `HTTP/gRPC`) used for triggering the pipeline. In this tutorial, we will use the HTTP protocol as an example to demonstrate how to parse the responses from a `SYNC` pipeline.

## How to process pipeline responses

Let's go back to our code in `sync-http-base64.py`. After triggering a `SYNC` pipeline, the function will return a response from your triggered pipeline. 

```python
# Post HTTP request to the SYNC pipeline
resp = trigger_pipeline_multipart(pipeline_backend_url, pipeline_id, img_folder, img_names)

# Parse results from the SYNC pipeline
boxes_ltwh, categories, scores = parse_detection_response(resp)
```

Here, the pipeline responds to our HTTP POST request with `resp: request.Response`, which is then passed to a user-defined parser `parse_detection_response(resp)` to extract object detection results. You can find corresponding parsers in our examples per VDP standardised AI task.

In the parsers, you can write code to convert the JSON object `resp` to a Python object for easy access using the one-line code below, where `resp.text` returns the response's content in Unicode in Python 3.

```python
# Parse JSON into a Python object with attributes corresponding to dict keys.
r = json.loads(resp.text, object_hook=lambda d: SimpleNamespace(**d))
```


### Pipeline response in `SYNC` mode

To better understand what is in the `resp`, let's have a closer look at `resp.text`, the content of the `SYNC` mode response in JSON format:

```python
## This is the object returned in SYNC mode.
{
   "data_mapping_indices":[
      "01GPXG4P8MWZD4ZQMXD98CAEGG"
   ],
   "model_instance_outputs":[
      {
         "model_instance":"models/yolov7/instances/v1.0-cpu",
         "task":"TASK_DETECTION",
         "task_outputs":[
            {
               "index":"01GPXG4P8MWZD4ZQMXD98CAEGG",
               "detection":{
                  "objects":[
                     {
                        "category":"dog",
                        "score":0.9597808,
                        "bounding_box":{
                           "top":102,
                           "left":324,
                           "width":208,
                           "height":405
                        }
                     },
                     {
                        "category":"dog",
                        "score":0.92909366,
                        "bounding_box":{
                           "top":198,
                           "left":130,
                           "width":198,
                           "height":237
                        }
                     }
                  ]
               }
            }
         ]
      }
   ]
}
```

- `data_mapping_indices`: is the pipeline trigger ID. You probably don't need this ID in the `SYNC` mode, as you receive responses right after you trigger pipelines. However, in the `ASYNC` and `PULL` modes, where pipelines do not return with model inference results immediately, users need this ID to locate corresponding results in the destination (e.g., database). 
- `model_instance_outputs`: is a list of outputs that users generated by triggering a pipeline with a batch of data. Taking object detection as an example, if you pass three images to the pipeline, it will return a list consisting of three outputs.

:::info{type=info}
We will show you how to locate corresponding results in `ASYNC` pipelines in [VDP 101 - 7. Create, Trigger and Retrieve Data from ASYNC pipelines].
:::

#### Model instance outputs

- `model_instance` is the model instance you defined when creating the pipeline.
- `task` is the name defined by the VDP model backend. You can identify the AI task performed using it. For those unspecified tasks defined by users, VDP returns `TASK_UNSPECIFIED`. Note that when [importing customised models](https://www.instill.tech/docs/import-models/overview), users need to [define model card](/docs/prepare-models/model-card) corresponding to their AI tasks.
- `task_outputs`: is a list of outputs given different tasks.
    - `index`: is the same as the `data_mapping_indices` received when triggering pipelines. Users can use it to match trigger queries and task outputs in `ASYNC` and `PULL` modes.
    - `detection`: is the **key** representing the AI task. Here, **detection** indicates this is an **object-detection** task.

#### Task outputs `objects`
- `object`: is a list of detection results. VDP defines different JSON objects with which users can easily read/parse the model outputs for popular AI tasks. 

:::info{type=info}
VDP currently standardises task outputs for popular AI tasks. You can find details for each AI task in [VDP standardised AI Tasks](/docs/core-concepts/ai-task).
:::

### Pipeline responses in `ASYNC` and `PULL` modes

Unlike in `SYNC` mode, the pipeline responses in `ASYNC`  and `PULL` modes are simple (as in the example shown below).  As seen, `model_instance_outputs` is an **empty** list. Users only receive  `data_mapping_indices`, which can match the outputs in the destinations (e.g., databases or spreadsheets).

```python
## This is the object returned in ASYNC and PULL modes.
{  
	"data_mapping_indices": [  
		"01GDR4ZW7W4T2H2G8MK79Y49PG",  
		"01GDR4ZW7W4T2H2G8MK8AR1T2B"  
	],  
	"model_instance_outputs": []  
}
```


### Unspecified Tasks

VDP can't standardise all possible AI tasks and their inputs and outputs. Therefore, it allows users to deploy their models even if VDP has yet to standardise the task. These models will be classified as `Unspecified` tasks. When an unspecified model in deployed, VDP will
 - check the `config.pbtxt` [model configuration](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html) file when [deploying customised model on VDP] to extract the output names, datatypes, and shapes of the model outputs,
 - and wrap this information along with the raw model output in a _standard_ format, as in the example below.

```python
## This is an example of the model outputs of undefined tasks.
{  
	"unspecified": {  
		"raw_outputs": [  
			{  
				"data": [0.85, 0.1, 0.05],  
				"data_type": "FP32",  
				"name": "output_scores",  
				"shape": [3]  
			},  
			{  
				"data": ["dog", "cat", "rabbit"],  
				"data_type": "BYTES",  
				"name": "output_labels",  
				"shape": [3]  
			}  
		]  
	}  
}
```

:::info{type=info} 
VDP exploits Triton Inference Server as the model inference backbone. Don't worry about how to import models to VDP just yet. We will discuss this in [VDP 101 - Import Model to VDP]. 
:::

## AI Tasks currently standardised by VDP

At the moment, VDP standardises the task outputs for popular AI tasks:

-   _Image classification_ - classify images into predefined categories
-   _Object detection_ - detect and localise multiple objects in images
-   _Keypoint detection_ - detect and localise multiple key points of objects in images
-   _OCR (Optical Character Recognition)_ - detect and recognise text in images
-   _Instance segmentation_ - detect, localise and delineate multiple objects in images
-   *Semantic Segmentation -* recognise a collection of image pixels that form distinct categories.
-   The list is growing ... ðŸŒ±

A complete list can be found on [VDP standardised AI Tasks](https://www.instill.tech/docs/core-concepts/ai-task).

We have demonstrated how to use VDP step-by-step in `SYNC` mode. However, VDP supports other modes, including `ASYNC` and `PULL`. Before showing how they work, let's closely look at their differences in our following tutorial â†’ [VDP 101 - 6. Pipeline Modes: SYNC, ASYNC, and PULL](/tutorials/vdp-101-6-pipeline-modes).

<br/><br/>
**â†“â†“â†“ VDP 101 TUTORIALS â†“â†“â†“**
1. [Introduction to VDP](/tutorials/vdp-101-1-introduction)
2. [Install VDP on Your Local Machine](/tutorials/vdp-101-2-installation)
3. [Create Your First Pipeline on VDP](/tutorials/vdp-101-3-create-your-first-pipeline)
4. [How to Trigger a SYNC Pipeline](/tutorials/vdp-101-4-how-to-trigger-a-sync-pipeline)
5. [How to Parse Responses from SYNC Pipelines](/tutorials/vdp-101-5-how-to-parse-vdp-responses)
6. [Pipeline Modes: SYNC, ASYNC, and PULL](/tutorials/vdp-101-6-pipeline-modes)