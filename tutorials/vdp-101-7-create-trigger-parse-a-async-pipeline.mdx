---
title: "VDP 101 [7/7] Create, Trigger, and Parse an ASYNC Pipeline"
lang: "en-US"
draft: false
description: "VDP supports pipelines in ASYNC mode. This tutorial will demonstrate how to build an end-to-end ASYNC pipeline using the same objective detection model."
aiTask: "Null"
sourceConnector: "HTTP"
destinationConnector: "HTTP"
publishedOn: "2023-01-30T19:32:00"
placeholderColor: "bg-instillYellow50"
themeImgSrc: "/tutorial-assets/vdp-101/cover-animation.gif"
themeImgThumbnailSrc: "/tutorial-assets/vdp-101/cover-static.png"
useCase: "Quickstart"
author: "Po-Yu Chen"
authorAvatarSrc: "/author-avatar/po-yu-chen.jpg"
authorGitHubUrl: "https://github.com/bryan107"
---

VDP supports pipelines in `ASYNC` mode. In this mode, users can trigger pipelines by sending requests. After the model instances process data, the outputs will be loaded to the designated destination asynchronously. This tutorial will demonstrate how to build an end-to-end `ASYNC` pipeline using the same objective detection model.

## 1. Prerequisites

In this tutorial, we'll use the same development environment below as in our previous tutorials.

- VDP
- Docker and Docker Compose
- Conda Environment
- Install required dependencies with

```bash
# move to the example directory for the VDP-101 ASYNC tutorial.
cd /example/vdp-101/async
# install dependencies.
pip install -r requirement.txt
```

You can manage these dependencies with a Conda environment. For further information, we refer users to [anaconda](https://docs.anaconda.com/anaconda/install/silent-mode/) or [miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html#installing-conda-on-a-system-that-has-other-python-installations-or-packages).

## 2. Create a new database in Postgres

Before setting up an `ASYNC` pipeline, we need to set up a database for **loading** our pipeline outputs. By default, VDP runs Postgres database services using Docker Container `pg-sql`. You can check it in our **Docker Desktop** or using the command line below.

```bash
# list all the docker containers.
docker ps
```

To create a database, we first SSH to Docker Container

```bash
# ssh into Docker Container named pg-sql.
docker exec -it pg-sql /bin/bash
```

Log into Postgres using the default username and **CREATE** a database named `tutorial`. Make sure there is a **";"** at the end of your SQL command.

```bash
# Log into Postgres.
psql -U postgres
# Create a new database named "tutorial."
CREATE database tutorial;
```

Check if `tutorial` is successfully created by checking if it is on the list.

```bash
# list all databases in Postgres DB.
\l
```

â†“â†“â†“ You should see a database named `tutorial` in the table below â†“â†“â†“

<img
  src="/tutorial-assets/vdp-101/7-async-pipeline/create-postgres-db.png"
  alt="list all databases in Postgres DB."
/>

Once you see it in your Postgres, close the terminal, and we are ready to create our first `ASYNC` pipeline on VDP.

## 3. Create an `ASYNC` pipeline

Open your local VDP console ([http://localhost:3000](http://localhost:3000)), and click `Add new pipeline`. To set up an `ASYNC` pipeline for this tutorial,

1. **Source**: select `Async` for **Pipeline mode** and select `HTTP` for **Source type**.
2. **Model Instance**: select `yolov7`under **Select an existing online model instance**
3. **Destination**: set up a new destination to the **Postgres database** we just created. Below is the setting we use in this example. **Host** should be your local IP address while **Username** and **Password** are default Postgres login which you can change as to your requirement.
4. **Pipeline**: set **ID** to `vdp-101-async`.

<img
  src="/tutorial-assets/vdp-101/7-async-pipeline/async-add-destination.png"
  alt="Set up destination to the database in Postgres DB."
/>

â†“â†“â†“ Check if the pipeline is activated on the **Pipeline** page â†“â†“â†“

<img
  src="/tutorial-assets/vdp-101/7-async-pipeline/async-pipeline-list.png"
  alt="Set up destination to the database in Postgres DB."
/>

Suppose you see a green light in front of the `vdp-101-asyn` pipeline, WHALA! You have just set up an `ASYNC` pipeline.

## 4. Trigger the ASYNC pipeline

Now would like to trigger the `ASYNC` pipeline we just created by running the script below.

```bash
# tigger the ASYNC pipeline we just created
python trigger.py
```

This script first downloads a video `cows_dornick.mp4` to the `async` folder, extracts frames from the video file, and saves these frames to the `async/input` folder. Once the extraction is complete, the script triggers the pipeline with image batches using _HTTP Multipart POST Requests_.

The pipeline responds with the **indices** (corresponding to each image), which are ultimately saved to an output file `data-mapping-indices.txt` under the `async` fold by default.

Unlike the responses in the `SYNC` mode, the `ASYNC` pipeline only responds with `data_mapping_indices` for each uploaded data.

```python
## This is the object returned in ASYNC and PULL modes.
{
	"data_mapping_indices": [
		"01GDR4ZW7W4T2H2G8MK79Y49PG",
		"01GDR4ZW7W4T2H2G8MK8AR1T2B"
	],
	"model_instance_outputs": []
}

```

After All the images are uploaded to the pipeline, you can check the indices using the command below:

```bash
# preview the request index file.
cat data-mapping-indices.txt
```

### Additional command line arguments

The script `trigger.py` provides command-line arguments below.

- `--pipeline`: Pipeline ID on VDP. Default `vdp-101-async`.
- `--framerate`: Frame rate of the video. Default `30`.
- `--batch-size`: Batch size of the multipart payload. Default `2`.
- `--mapping-file`: File stores the mapping indices for pipeline triggers. Default `data-mapping-indices.txt`.
- `--backend`: The IP and port of the backend pipeline service. Default `localhost:8081`.

You can find further details of these arguments in `README.md` under the `async` folder.

:::info{type=warning}
VDP limits the maximum image size to 12MB by default.
:::

## 5. Retrieve and output inference results from Database

After the `vdp-101-async` pipeline has processed all the uploaded images for the object detection task, we can download the inference result from the database with the `data-mapping-indices` we saved locally. Run the script below to download and visualise the result of the pipeline outputs.

```bash
# download and visualise the results from the database.
python process.py
```

This script exploits the indices stored in the `data-mapping-indices.txt` to locate the corresponding object detection results for each frame stored in `async/output`.

WHALA! Once everything is processed, you should find the output video `output.mp4` under the `async/outputs` folder. This script combines the object detection blocks with their corresponding frames and generates a video below as the final output.

<Youtube id="jokydabr70M" />

### Additional command line arguments

The script `process.py` provides command-line arguments below. Users can also change these settings in the `process.py`.

- `--host`: IP address of the Postgres host. Default `localhost`.
- `--port`: Postgres service port. Default `5432`.
- `--database`: Name of the database. Default `tutorial`.
- `--username`: Login username. Default `postgres`.
- `--password`: Login password. Default `password`.
- `--output`: Output video file name. Default `output.mp4`.
- `--framerate`: Frame rate of the video. Default `30`.

:::info{type=warning}
When setting `--host`, users may need to indicate with **actual** IP address instead of **localhost** to access the Postgres database running in a docker container.
:::

## 6. Conclusion

In this tutorial, you've built an ASYNC object detection pipeline using VDP to process a video and sent the analysis result to a Postgres database.

If you enjoyed VDP, we're building a fully managed service for VDP - **Instill Cloud (Alpha)**:

- Painless setup
- Maintenance-free infrastructure
- Start for free, pay as you grow

<CtaButton
  text="ðŸš€ Join the Instill Cloud waitlist."
  link="https://www.instill.tech/get-access/?utm_source=tutorial&utm_medium=link&utm_campaign=vdp-streamlit-yolov7"
/>

We also invite you to join our [Discord community](http://go.instill.tech/4fajhm) to share your use cases and showcase your work with Data/AI practitioners.

<br />
<br />
**â†“â†“â†“ VDP 101 - Get familiar with the basics â†“â†“â†“** - [[1/7] Introduction to
VDP](/tutorials/vdp-101-1-introduction) - [[2/7] Install VDP on Your Local
Machine](/tutorials/vdp-101-2-quickstart) - [[3/7] Create Your First Pipeline on
VDP](/tutorials/vdp-101-3-create-your-first-pipeline) - [[4/7] How to Trigger a
SYNC Pipeline](/tutorials/vdp-101-4-how-to-trigger-a-sync-pipeline) - [[5/7] How
to Parse Responses from SYNC
Pipelines](/tutorials/vdp-101-5-how-to-parse-vdp-responses) - [[6/7] Pipeline
Modes: SYNC, ASYNC, and PULL](/tutorials/vdp-101-6-pipeline-modes) - [[7/7]
Create, Trigger, and Parse an ASYNC
Pipeline](/tutorials/vdp-101-7-create-trigger-parse-a-async-pipeline)
